import { OpenAI } from "openai";
import { Pinecone } from "@pinecone-database/pinecone";
import { NextResponse } from "next/server";
import * as cheerio from 'cheerio';
import * as xlsx from 'xlsx';
import mammoth from 'mammoth';
// const pdf = require('pdf-parse');

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const pinecone = new Pinecone({
    apiKey: process.env.PINECONE_API_KEY!,
});

export async function POST(req: Request) {
    try {
        console.log("API: Received knowledge request");
        const body = await req.json();
        const { text, chatbotId, docId, type, url, fileBase64, fileName } = body;
        console.log("API: Parsed body", { chatbotId, docId, type, fileName, hasFile: !!fileBase64 });

        if (!chatbotId) {
            return NextResponse.json({ error: "Missing chatbotId" }, { status: 400 });
        }

        // Enforce docId for consistency
        if (!docId) {
            return NextResponse.json({ error: "Missing docId" }, { status: 400 });
        }

        let contentToEmbed = text;
        let title = fileName || "";
        let preview = "";

        // Handle URL Type
        if (type === 'url') {
            if (!url) return NextResponse.json({ error: "Missing URL" }, { status: 400 });

            try {
                // If text is already provided (from preview), use it. Otherwise scrape.
                if (!text) {
                    const response = await fetch(url);
                    const html = await response.text();
                    const $ = cheerio.load(html);

                    // Remove scripts, styles, etc.
                    $('script').remove();
                    $('style').remove();
                    $('nav').remove();
                    $('footer').remove();
                    $('header').remove();

                    title = $('title').text() || url;
                    // Get text content
                    contentToEmbed = $('body').text().replace(/\s+/g, ' ').trim();
                }

                preview = contentToEmbed.substring(0, 200) + "...";

                if (!contentToEmbed || contentToEmbed.length < 50) {
                    return NextResponse.json({ error: "Could not extract enough text from URL" }, { status: 400 });
                }

            } catch (e) {
                console.error("Scraping error:", e);
                return NextResponse.json({ error: "Failed to scrape URL" }, { status: 500 });
            }
        } else if (type === 'file') {
            console.log("API: Processing file upload");
            if (!fileBase64) return NextResponse.json({ error: "Missing file data" }, { status: 400 });

            try {
                const buffer = Buffer.from(fileBase64, 'base64');
                console.log("API: File buffer created, size:", buffer.length);

                if (fileName.endsWith('.pdf')) {
                    console.log("API: Parsing PDF...");

                    // Import directly from lib to avoid index.js side-effect (isDebugMode check)
                    const pdfParse = require('pdf-parse/lib/pdf-parse.js');

                    const data = await pdfParse(buffer);
                    console.log("API: PDF parsed, text length:", data.text.length);
                    contentToEmbed = data.text;
                } else if (fileName.endsWith('.xlsx') || fileName.endsWith('.xls')) {
                    console.log("API: Parsing Excel...");
                    const workbook = xlsx.read(buffer, { type: 'buffer' });
                    let excelText = "";

                    workbook.SheetNames.forEach(sheetName => {
                        const sheet = workbook.Sheets[sheetName];
                        // Convert sheet to CSV to preserve some structure
                        const sheetCsv = xlsx.utils.sheet_to_csv(sheet);
                        excelText += `\n--- Sheet: ${sheetName} ---\n${sheetCsv}`;
                    });

                    console.log("API: Excel parsed, text length:", excelText.length);
                    contentToEmbed = excelText;
                } else if (fileName.endsWith('.docx')) {
                    console.log("API: Parsing Word...");
                    const result = await mammoth.extractRawText({ buffer: buffer });
                    console.log("API: Word parsed, text length:", result.value.length);
                    if (result.messages.length > 0) {
                        console.log("API: Mammoth messages:", result.messages);
                    }
                    contentToEmbed = result.value;
                } else {
                    // Assume text file
                    contentToEmbed = buffer.toString('utf-8');
                }

                // Clean up text
                contentToEmbed = contentToEmbed.replace(/\s+/g, ' ').trim();
                preview = contentToEmbed.substring(0, 200) + "...";

                if (!contentToEmbed || contentToEmbed.length < 20) {
                    return NextResponse.json({ error: "Could not extract text from file" }, { status: 400 });
                }

            } catch (e) {
                console.error("File parsing error:", e);
                return NextResponse.json({ error: "Failed to parse file: " + e }, { status: 500 });
            }
        } else {
            // Text Type
            if (!text) {
                return NextResponse.json({ error: "Missing text" }, { status: 400 });
            }
        }

        console.log("API: Generating embeddings...");

        // Simple chunking function
        function chunkText(text: string, chunkSize: number = 4000): string[] {
            const chunks = [];
            for (let i = 0; i < text.length; i += chunkSize) {
                chunks.push(text.slice(i, i + chunkSize));
            }
            return chunks;
        }

        const chunks = chunkText(contentToEmbed);
        console.log(`API: Split text into ${chunks.length} chunks`);

        // Process chunks in batches to avoid rate limits
        const vectors = [];

        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            const embeddingResponse = await openai.embeddings.create({
                model: "text-embedding-3-small",
                input: chunk,
                encoding_format: "float",
            });

            const embedding = embeddingResponse.data[0].embedding;
            // Use docId in the vector ID for easier debugging, but rely on metadata for deletion
            const chunkId = `${docId}-${i}`;

            vectors.push({
                id: chunkId,
                values: embedding,
                metadata: {
                    chatbotId,
                    docId, // CRITICAL: Store docId in metadata for deletion
                    text: chunk,
                    type: type || 'text',
                    source: url || fileName || 'manual',
                    title: `${title || 'Untitled'} (Part ${i + 1})`,
                    chunkIndex: i,
                    totalChunks: chunks.length
                },
            });
        }

        // 2. Save to Pinecone (batch upsert)
        const index = pinecone.index("chatbot-knowledge");

        // Upsert in batches of 10 to be safe
        const batchSize = 10;
        for (let i = 0; i < vectors.length; i += batchSize) {
            const batch = vectors.slice(i, i + batchSize);
            await index.upsert(batch);
        }

        console.log("API: Saved all chunks to Pinecone");

        return NextResponse.json({ success: true, title, preview, vectorId: vectors[0].id, chunkCount: chunks.length });

    } catch (error) {
        console.error("Ingestion error:", error);
        return NextResponse.json({ error: "Internal Server Error: " + error }, { status: 500 });
    }
}

export async function DELETE(req: Request) {
    try {
        const { searchParams } = new URL(req.url);
        const docId = searchParams.get("docId");
        const chatbotId = searchParams.get("chatbotId");

        if (!docId || !chatbotId) {
            return NextResponse.json({ error: "Missing docId or chatbotId" }, { status: 400 });
        }

        console.log(`API: Deleting doc ${docId} for chatbot ${chatbotId}`);

        const index = pinecone.index("chatbot-knowledge");

        // Delete by metadata filter
        await index.deleteMany({
            chatbotId: chatbotId,
            docId: docId
        });

        console.log("API: Deleted vectors from Pinecone");

        return NextResponse.json({ success: true });

    } catch (error) {
        console.error("Delete error:", error);
        return NextResponse.json({ error: "Delete failed" }, { status: 500 });
    }
}
